{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T18:00:15.864914Z",
     "start_time": "2019-08-27T12:52:27.633794Z"
    },
    "code_folding": [
     28
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searched keyword : bawaslu\n",
      "since date [YYYY-MM-DD]: 2019-05-14\n",
      "until date [YYYY-MM-DD]: 2019-05-27\n",
      "Data bawaslu loaded!\n",
      "Data bawaslu tweets parsed!\n",
      "Data bawaslu users parsed!\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from dateutil.parser import parse\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def udf_wrapper(returntype):\n",
    "    def udf_func(func):\n",
    "        return udf(func, returnType=returntype)\n",
    "    return udf_func\n",
    "\n",
    "@udf_wrapper(StringType())\n",
    "def tweet_source(s):\n",
    "    return re.findall(r'\\>(.+)\\<', s)[0]\n",
    "\n",
    "@udf_wrapper(StringType())\n",
    "def blank_as_null(x):\n",
    "    return when(x != None, col(x)).otherwise(None)\n",
    "\n",
    "@udf_wrapper(StructType([StructField('user_city', StringType()),\n",
    "                         StructField('user_province', StringType())\n",
    "                        ]))\n",
    "def location_lookup(loc):\n",
    "        city_look = pd.read_csv('lookup/city_lookup.csv')\n",
    "        city_look['keyword'] = city_look['keyword'].str.upper()\n",
    "        province_look = pd.read_csv('lookup/province_lookup.csv')\n",
    "        province_look['keyword'] = province_look['keyword'].str.upper()\n",
    "        subdistrict_look = pd.read_csv('lookup/sub_district_lookup.csv')\n",
    "        subdistrict_look['keyword'] = subdistrict_look['keyword'].str.upper()\n",
    "        city = 'Undefined'\n",
    "        prov = 'Undefined'\n",
    "        if loc != 'UNDEFINED':\n",
    "            for c in range(len(city_look)):\n",
    "                if city_look['keyword'][c] in loc:\n",
    "                    city = city_look['city'][c]\n",
    "                    prov = city_look['state'][c]\n",
    "                    break\n",
    "\n",
    "            if ((city == 'Undefined') & (prov == 'Undefined')):\n",
    "                for p in range(len(province_look)):\n",
    "                    if province_look['keyword'][p] in loc:\n",
    "                        city = province_look['city'][p]\n",
    "                        prov = province_look['state'][p]\n",
    "                        break    \n",
    "                        \n",
    "            if ((city == 'Undefined') & (prov == 'Undefined')):\n",
    "                for s in range(len(subdistrict_look)):\n",
    "                    if subdistrict_look['keyword'][s] in loc:\n",
    "                        city = subdistrict_look['city'][s]\n",
    "                        prov = subdistrict_look['state'][s]\n",
    "                        break\n",
    "        return {\n",
    "                'user_city': city,\n",
    "                'user_province': prov\n",
    "               }\n",
    "\n",
    "def tweet_parser(tweets_data):\n",
    "    # Select used fields\n",
    "    tweets = tweets_data.selectExpr('created_at_local as created_at',\n",
    "                                    'id_str as tweet_id',\n",
    "                                    'user.id_str as user_id',\n",
    "                                    'user.screen_name as user_screenname',\n",
    "                                    'user.friends_count as user_followings_count',\n",
    "                                    'user.followers_count as user_followers_count',\n",
    "                                    'user.statuses_count as user_tweets_count',\n",
    "                                    'user.location as user_location',\n",
    "                                    'user.verified as is_verified',\n",
    "                                    'full_text as tweet_text', \n",
    "                                    'favorite_count', \n",
    "                                    'retweet_count',\n",
    "                                    'source as tweet_source',\n",
    "                                    'place.full_name as place_fullname',\n",
    "                                    'place.name as place_name',\n",
    "                                    'place.place_type as place_type',\n",
    "                                    'place.country as place_country',\n",
    "                                    'quoted_status.id_str as quoted_from_tweet_id', \n",
    "                                    'quoted_status.user.id_str as quoted_from_user_id',\n",
    "                                    'quoted_status.user.screen_name as quoted_from_user_screenname',\n",
    "                                    'in_reply_to_status_id_str as reply_to_tweet_id',\n",
    "                                    'in_reply_to_user_id_str as reply_to_user_id',\n",
    "                                    'in_reply_to_screen_name as reply_to_user_screenname',\n",
    "                                    'retweeted_status.id_str as retweeted_from_tweet_id', \n",
    "                                    'retweeted_status.user.id_str as retweeted_from_user_id',\n",
    "                                    'retweeted_status.user.screen_name as retweeted_from_user_screenname',)\n",
    "\n",
    "    # Collect original tweets\n",
    "    origin = tweets.where(col(\"quoted_from_tweet_id\").isNull())\\\n",
    "                   .where(col(\"reply_to_tweet_id\").isNull())\\\n",
    "                   .where(col(\"retweeted_from_tweet_id\").isNull())\\\n",
    "                   .withColumn('tweet_type', lit('tweet'))\\\n",
    "                   .withColumn('tweet_source', tweet_source('tweet_source'))\n",
    "\n",
    "    # Collect reply to tweets\n",
    "    reply = tweets.where(col(\"quoted_from_tweet_id\").isNull())\\\n",
    "                  .where(col(\"reply_to_tweet_id\").isNotNull())\\\n",
    "                  .where(col(\"retweeted_from_tweet_id\").isNull())\\\n",
    "                  .withColumn('tweet_type', lit('reply'))\\\n",
    "                  .withColumn('tweet_source', tweet_source('tweet_source'))\n",
    "\n",
    "    # Collect quoted from tweets\n",
    "    quote = tweets.where(col(\"quoted_from_tweet_id\").isNotNull())\\\n",
    "                  .where(col(\"reply_to_tweet_id\").isNull())\\\n",
    "                  .where(col(\"retweeted_from_tweet_id\").isNull())\\\n",
    "                  .withColumn('tweet_type', lit('quote'))\\\n",
    "                  .withColumn('tweet_source', tweet_source('tweet_source'))\n",
    "\n",
    "    # Collect retweeted from tweets\n",
    "    retweet = tweets.where(col(\"quoted_from_tweet_id\").isNull())\\\n",
    "                    .where(col(\"reply_to_tweet_id\").isNull())\\\n",
    "                    .where(col(\"retweeted_from_tweet_id\").isNotNull())\\\n",
    "                    .withColumn('tweet_type', lit('retweet'))\\\n",
    "                    .withColumn('tweet_source', tweet_source('tweet_source'))\\\n",
    "                    .withColumn('retweet_count', lit(0))\\\n",
    "                    .withColumn('favorite_count', lit(0))\n",
    "\n",
    "    # Collect retweeted from quoted tweets\n",
    "    retweet_from_quote = tweets.where(col(\"quoted_from_tweet_id\").isNotNull())\\\n",
    "                               .where(col(\"reply_to_tweet_id\").isNull())\\\n",
    "                               .where(col(\"retweeted_from_tweet_id\").isNotNull())\\\n",
    "                               .withColumn('tweet_type', lit('retweet'))\\\n",
    "                               .withColumn('tweet_source', tweet_source('tweet_source'))\\\n",
    "                               .withColumn('retweet_count', lit(0))\\\n",
    "                               .withColumn('favorite_count', lit(0))\n",
    "\n",
    "    # Collect reply from quoted tweets\n",
    "    reply_from_quote = tweets.where(col(\"quoted_from_tweet_id\").isNotNull())\\\n",
    "                             .where(col(\"reply_to_tweet_id\").isNotNull())\\\n",
    "                             .where(col(\"retweeted_from_tweet_id\").isNull())\\\n",
    "                             .withColumn('tweet_type', lit('reply'))\\\n",
    "                             .withColumn('tweet_source', tweet_source('tweet_source'))\n",
    "\n",
    "    tweets = origin.union(reply).union(quote).union(retweet).union(retweet_from_quote).union(reply_from_quote)\n",
    "            \n",
    "    tweets = tweets.toPandas()\n",
    "    \n",
    "    is_id = ['tweet_id','user_id','quoted_from_tweet_id',\n",
    "             'quoted_from_user_id','reply_to_tweet_id',\n",
    "             'reply_to_user_id','retweeted_from_tweet_id',\n",
    "             'retweeted_from_user_id']\n",
    "    for i in is_id:\n",
    "        tweets[i] = tweets[i].apply(lambda x: '_'+x if x != None else x)\n",
    "    tweets = tweets[['created_at', 'tweet_id', 'user_id', 'user_screenname',\n",
    "                     'user_followings_count', 'user_followers_count', 'user_tweets_count',\n",
    "                     'user_location', 'is_verified', 'tweet_text', 'favorite_count',\n",
    "                     'retweet_count', 'tweet_source', 'tweet_type', \n",
    "                     'place_fullname', 'place_name',\n",
    "                     'place_type', 'place_country', 'quoted_from_tweet_id',\n",
    "                     'quoted_from_user_id', 'quoted_from_user_screenname',\n",
    "                     'reply_to_tweet_id', 'reply_to_user_id', 'reply_to_user_screenname',\n",
    "                     'retweeted_from_tweet_id', 'retweeted_from_user_id',\n",
    "                     'retweeted_from_user_screenname']]\n",
    "    tweets = tweets.drop_duplicates(subset=['tweet_id']).reset_index(drop=True)\n",
    "    tweets.to_csv('{}/spark_collection_of_tweets_{}_{}-{}.csv'.format(path, \n",
    "                                                         keyword_search, \n",
    "                                                         since.replace('-',''), \n",
    "                                                         until.replace('-','')),\n",
    "                  index=False)\n",
    "    return tweets\n",
    "\n",
    "def user_parser(tweets_data):\n",
    "    users = tweets_data.selectExpr('user.id_str as user_id',\n",
    "                                   'user.name as user_fullname',\n",
    "                                   'user.screen_name as user_screenname',\n",
    "                                   'user.created_at as user_created_at',\n",
    "                                   'user.friends_count as user_followings_count',\n",
    "                                   'user.followers_count as user_followers_count',\n",
    "                                   'user.statuses_count as user_tweets_count',\n",
    "                                   'user.location as user_location',\n",
    "                                   'user.verified as is_verified')\n",
    "    users = users.dropDuplicates(subset=['user_id'])\n",
    "    users = users.withColumn('user_location', location_lookup('user_location'))\n",
    "    users = users.selectExpr(\n",
    "                             'user_id',\n",
    "                             'user_fullname',\n",
    "                             'user_screenname',\n",
    "                             'user_created_at',\n",
    "                             'user_followings_count',\n",
    "                             'user_followers_count',\n",
    "                             'user_tweets_count',\n",
    "                             'user_location.user_city as user_city',\n",
    "                             'user_location.user_province as user_province',\n",
    "                             'is_verified'\n",
    "                            )\n",
    "    users = users.toPandas()\n",
    "    users['user_id'] = users['user_id'].apply(lambda x: '_'+x)\n",
    "    users['user_created_at'] = users['user_created_at'].apply(lambda x: (parse(x, ignoretz=True) + timedelta(hours=7)).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    users = users[['user_id','user_screenname','user_fullname','user_created_at',\n",
    "                   'user_followings_count','user_followers_count','user_tweets_count',\n",
    "                   'user_city','user_province','is_verified']]\n",
    "    users.to_csv('{}/spark_collection_of_users_{}_{}-{}.csv'.format(path, \n",
    "                                                   keyword_search, \n",
    "                                                   since.replace('-',''), \n",
    "                                                   until.replace('-','')),\n",
    "                 index=False)\n",
    "    return users\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Create spark session\n",
    "    conf = pyspark.SparkConf().setAll([('spark.executor.memory', '8g'), \n",
    "                                       ('spark.driver.memory','10g'), \n",
    "                                       ('spark.driver.maxResultSize','20g'), \n",
    "                                       (\"spark.ui.showConsoleProgress\", \"false\")])\n",
    "    sc = SparkSession.builder.config(conf=conf).master('local[6]').appName('Spark Tweets Parser').getOrCreate()\n",
    "    \n",
    "    keyword_search = input('searched keyword : ')\n",
    "    since = input('since date [YYYY-MM-DD]: ')\n",
    "    until = input('until date [YYYY-MM-DD]: ')\n",
    "\n",
    "    # Load Tweets Data\n",
    "    print('Load data...', end='\\r')\n",
    "    path = '{}/tweet_search_result/{}'.format(os.getcwd(), keyword_search)\n",
    "    tweets_data = sc.read.json('{}/*.json'.format(path).split(','))\n",
    "    print('Data {} loaded!'.format(keyword_search))\n",
    "\n",
    "    # Filter by Date\n",
    "    tweets_data = tweets_data.filter(col(\"created_at_local\") >= \"{} 00:00:00\".format(since))\\\n",
    "                             .filter(col(\"created_at_local\") <= \"{} 23:59:59\".format(until))\n",
    "\n",
    "    # Parsing required fields for analysis\n",
    "    print('Parsing tweets...', end='\\r')\n",
    "    tweets = tweet_parser(tweets_data)\n",
    "    print('Data {} tweets parsed!'.format(keyword_search))\n",
    "\n",
    "    print('Parsing users...', end='\\r')\n",
    "    users = user_parser(tweets_data)\n",
    "    print('Data {} users parsed!'.format(keyword_search))\n",
    "    \n",
    "    sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
